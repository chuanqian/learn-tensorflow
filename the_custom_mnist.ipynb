{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7a64e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a8f2cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.10.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensorflow version: {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45517701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取mnist数据集\n",
    "(train_image, train_label), (test_image, test_label) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "902aed7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc8cb446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 增加训练集和测试集的维度，并且做归一化\n",
    "train_image = tf.expand_dims(train_image, -1)\n",
    "test_image = tf.expand_dims(test_image, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74eccc67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([60000, 28, 28, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "891a6ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 改变数据类型，image为float32，label为int64\n",
    "train_image = tf.cast(train_image / 255, tf.float32)\n",
    "test_image = tf.cast(test_image / 255, tf.float32)\n",
    "train_label = tf.cast(train_label, tf.int64)\n",
    "test_label = tf.cast(test_label, tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b194528",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_image, train_label))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_image, test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf5be3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.shuffle(10000).batch(32)\n",
    "test_dataset = test_dataset.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "511a4791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63692de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型，并初始化\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(16, [3, 3], input_shape = (28, 28, 1), activation = \"relu\"),\n",
    "    layers.Conv2D(32, [3, 3], activation = \"relu\"),\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7aea539b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用优化器\n",
    "optimizer = keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf511c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数方法，调用即可\n",
    "loss_function = keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27757c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 迭代查看一个dataset的数据\n",
    "features, label = next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9b18ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 28, 28, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46db142b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32,), dtype=int64, numpy=\n",
       "array([6, 9, 7, 1, 2, 2, 8, 0, 5, 3, 8, 0, 0, 9, 7, 2, 5, 3, 9, 9, 0, 4,\n",
       "       6, 9, 9, 2, 6, 2, 7, 6, 9, 3], dtype=int64)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "602f7516",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fec7a37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 10])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7885025f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32,), dtype=int64, numpy=\n",
       "array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3], dtype=int64)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8c059f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个损失函数\n",
    "def loss(model, x, y):\n",
    "    # 预测的值为y_\n",
    "    y_ = model(x)\n",
    "    return loss_function(y, y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2202a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = keras.metrics.Mean(\"train_loss\")\n",
    "train_accuracy = keras.metrics.SparseCategoricalAccuracy(\"train_accuracy\")\n",
    "test_loss = keras.metrics.Mean(\"test_loss\")\n",
    "test_accuracy = keras.metrics.SparseCategoricalAccuracy(\"test_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65d4f8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一步训练数据集\n",
    "def train_setp(model, images, labels):\n",
    "    with tf.GradientTape() as t:\n",
    "        pred = model(images)\n",
    "        loss_step = loss_function(labels, pred)\n",
    "    grads = t.gradient(loss_step, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    train_loss(loss_step)\n",
    "    train_accuracy(labels, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "393fe561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model, images, labels):\n",
    "    pred = model(images,training=False)\n",
    "    loss_step = loss_function(labels, pred)\n",
    "    test_loss(loss_step)\n",
    "    test_accuracy(labels, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "382596a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 开始训练\n",
    "def train():\n",
    "    for epoch in range(10):\n",
    "        for (batch, (images, labels)) in enumerate(train_dataset):\n",
    "            train_setp(model, images, labels)\n",
    "        print(\"Epoch{} loss is {}, accuracy is {}\".format(epoch, \n",
    "                                                          train_loss.result(),\n",
    "                                                          train_accuracy.result()))\n",
    "        \n",
    "        \n",
    "        for (batch, (images, labels)) in enumerate(test_dataset):\n",
    "            test_step(model, images, labels)\n",
    "        print(\"Epoch{} test_loss is {}, test_accuracy is {}\".format(epoch, \n",
    "                                                          test_loss.result(),\n",
    "                                                          test_accuracy.result()))\n",
    "        \n",
    "        \n",
    "        train_loss.reset_states()\n",
    "        train_accuracy.reset_states()\n",
    "        test_loss.reset_states()\n",
    "        test_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "61ec51d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch0 loss is 0.9787788987159729, accuracy is 0.6949796080589294\n",
      "Epoch0 test_loss is 0.857010006904602, test_accuracy is 0.7325999736785889\n",
      "Epoch1 loss is 0.8332871794700623, accuracy is 0.750249981880188\n",
      "Epoch1 test_loss is 0.755294144153595, test_accuracy is 0.7682999968528748\n",
      "Epoch2 loss is 0.7381232380867004, accuracy is 0.7803333401679993\n",
      "Epoch2 test_loss is 0.6700170040130615, test_accuracy is 0.7896999716758728\n",
      "Epoch3 loss is 0.6676739454269409, accuracy is 0.8007500171661377\n",
      "Epoch3 test_loss is 0.6248553991317749, test_accuracy is 0.8062000274658203\n",
      "Epoch4 loss is 0.6115558743476868, accuracy is 0.8194166421890259\n",
      "Epoch4 test_loss is 0.5403087735176086, test_accuracy is 0.8395000100135803\n",
      "Epoch5 loss is 0.5652474164962769, accuracy is 0.8312666416168213\n",
      "Epoch5 test_loss is 0.5157349705696106, test_accuracy is 0.8457000255584717\n",
      "Epoch6 loss is 0.5282272696495056, accuracy is 0.8415833115577698\n",
      "Epoch6 test_loss is 0.48312732577323914, test_accuracy is 0.8555999994277954\n",
      "Epoch7 loss is 0.4946761429309845, accuracy is 0.8513500094413757\n",
      "Epoch7 test_loss is 0.4585031569004059, test_accuracy is 0.8654999732971191\n",
      "Epoch8 loss is 0.46773263812065125, accuracy is 0.8597333431243896\n",
      "Epoch8 test_loss is 0.4398716986179352, test_accuracy is 0.8687000274658203\n",
      "Epoch9 loss is 0.4406226575374603, accuracy is 0.8686333298683167\n",
      "Epoch9 test_loss is 0.3995940387248993, test_accuracy is 0.8858000040054321\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddc6078",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
